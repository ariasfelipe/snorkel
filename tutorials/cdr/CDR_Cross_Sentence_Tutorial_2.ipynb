{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chemical-Disease Relation (CDR) Tutorial\n",
    "\n",
    "In this example, we'll be writing an application to extract *mentions of* **chemical-induced-disease relationships** from Pubmed abstracts, as per the [BioCreative CDR Challenge](http://www.biocreative.org/resources/corpora/biocreative-v-cdr-corpus/).  This tutorial will show off some of the more advanced features of Snorkel, so we'll assume you've followed the Intro tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by reloading from the last notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from snorkel import SnorkelSession\n",
    "\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "ChemicalDisease = candidate_subclass('ChemicalDisease', ['chemical', 'disease'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: Writing LFs\n",
    "\n",
    "This tutorial features some more advanced LFs than the intro tutorial, with more focus on distant supervision and dependencies between LFs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distant supervision approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use the [Comparative Toxicogenomics Database](http://ctdbase.org/) (CTD) for distant supervision. The CTD lists chemical-condition entity pairs under three categories: therapy, marker, and unspecified. Therapy means the chemical treats the condition, marker means the chemical is typically present with the condition, and unspecified is...unspecified. We can write LFs based on these categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "from six.moves.cPickle import load\n",
    "\n",
    "with bz2.BZ2File('data/ctd.pkl.bz2', 'rb') as ctd_f:\n",
    "    ctd_unspecified, ctd_therapy, ctd_marker = load(ctd_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cand_in_ctd_unspecified(c):\n",
    "    return 1 if c.get_cids() in ctd_unspecified else 0\n",
    "\n",
    "def cand_in_ctd_therapy(c):\n",
    "    return 1 if c.get_cids() in ctd_therapy else 0\n",
    "\n",
    "def cand_in_ctd_marker(c):\n",
    "    return 1 if c.get_cids() in ctd_marker else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_in_ctd_unspecified(c):\n",
    "    if -1 * cand_in_ctd_unspecified(c) == -1:\n",
    "        return 2\n",
    "    else:\n",
    "        return -1 * cand_in_ctd_unspecified(c)\n",
    "\n",
    "def LF_in_ctd_therapy(c):\n",
    "    if -1 * cand_in_ctd_therapy(c) == -1:\n",
    "        return 2\n",
    "    else:\n",
    "        return -1 * cand_in_ctd_therapy(c)\n",
    "\n",
    "def LF_in_ctd_marker(c):\n",
    "    return cand_in_ctd_marker(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text pattern approaches\n",
    "\n",
    "Now we'll use some LF helpers to create LFs based on indicative text patterns. We came up with these rules by using the viewer to examine training candidates and noting frequent patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from snorkel.lf_helpers import (\n",
    "    cross_sentence_get_tagged_text,\n",
    "    cross_sentence_rule_regex_search_tagged_text,\n",
    "    cross_sentence_rule_regex_search_btw_AB,\n",
    "    cross_sentence_rule_regex_search_btw_BA,\n",
    "    cross_sentence_rule_regex_search_before_A,\n",
    "    cross_sentence_rule_regex_search_before_B,\n",
    "    get_sentences,\n",
    "    get_dep_path\n",
    ")\n",
    "\n",
    "# List to parenthetical\n",
    "def ltp(x):\n",
    "    return '(' + '|'.join(x) + ')'\n",
    "\n",
    "def LF_induce(c):\n",
    "    return 1 if re.search(r'{{A}}.{0,20}induc.{0,20}{{B}}', cross_sentence_get_tagged_text(c, session), flags=re.I) else 0\n",
    "\n",
    "causal_past = ['induced', 'caused', 'due']\n",
    "def LF_d_induced_by_c(c):\n",
    "    return cross_sentence_rule_regex_search_btw_BA(c, '.{0,50}' + ltp(causal_past) + '.{0,9}(by|to).{0,50}', 1, session)\n",
    "\n",
    "def LF_d_induced_by_c_tight(c):\n",
    "    return cross_sentence_rule_regex_search_btw_BA(c, '.{0,50}' + ltp(causal_past) + ' (by|to) ', 1, session)\n",
    "\n",
    "def LF_induce_name(c):\n",
    "    return 1 if 'induc' in c.chemical.get_span().lower() else 0     \n",
    "\n",
    "causal = ['cause[sd]?', 'induce[sd]?', 'associated with']\n",
    "def LF_c_cause_d(c):\n",
    "    return 1 if (\n",
    "        re.search(r'{{A}}.{0,50} ' + ltp(causal) + '.{0,50}{{B}}', cross_sentence_get_tagged_text(c, session), re.I)\n",
    "        and not re.search('{{A}}.{0,50}(not|no).{0,20}' + ltp(causal) + '.{0,50}{{B}}', cross_sentence_get_tagged_text(c, session), re.I)\n",
    "    ) else 0\n",
    "\n",
    "treat = ['treat', 'effective', 'prevent', 'resistant', 'slow', 'promise', 'therap']\n",
    "\n",
    "def LF_d_treat_c(c):\n",
    "    return cross_sentence_rule_regex_search_btw_BA(c, '.{0,50}' + ltp(treat) + '.{0,50}', 2, session)\n",
    "\n",
    "def LF_c_treat_d(c):\n",
    "    return cross_sentence_rule_regex_search_btw_AB(c, '.{0,50}' + ltp(treat) + '.{0,50}', 2, session)\n",
    "\n",
    "def LF_treat_d(c):\n",
    "    return cross_sentence_rule_regex_search_before_B(c, ltp(treat) + '.{0,50}', 2, session)\n",
    "\n",
    "def LF_c_treat_d_wide(c):\n",
    "    return cross_sentence_rule_regex_search_btw_AB(c, '.{0,200}' + ltp(treat) + '.{0,200}', 2, session)\n",
    "\n",
    "def LF_c_d(c):\n",
    "    return 1 if ('{{A}} {{B}}' in cross_sentence_get_tagged_text(c, session)) else 0\n",
    "\n",
    "def LF_c_induced_d(c):\n",
    "    return 1 if (\n",
    "        ('{{A}} {{B}}' in cross_sentence_get_tagged_text(c, session)) and \n",
    "        (('-induc' in c[0].get_span().lower()) or ('-assoc' in c[0].get_span().lower()))\n",
    "        ) else 0\n",
    "\n",
    "def LF_improve_before_disease(c):\n",
    "    return cross_sentence_rule_regex_search_before_B(c, 'improv.*', 2, session)\n",
    "\n",
    "pat_terms = ['in a patient with ', 'in patients with']\n",
    "def LF_in_patient_with(c):\n",
    "    return 2 if re.search(ltp(pat_terms) + '{{B}}', cross_sentence_get_tagged_text(c, session), flags=re.I) else 0\n",
    "\n",
    "uncertain = ['combin', 'possible', 'unlikely']\n",
    "def LF_uncertain(c):\n",
    "    return cross_sentence_rule_regex_search_before_A(c, ltp(uncertain) + '.*', 2, session)\n",
    "\n",
    "def LF_induced_other(c):\n",
    "    return cross_sentence_rule_regex_search_tagged_text(c, '{{A}}.{20,1000}-induced {{B}}', 2, session)\n",
    "\n",
    "def LF_far_c_d(c):\n",
    "    return cross_sentence_rule_regex_search_btw_AB(c, '.{100,5000}', 2, session)\n",
    "\n",
    "def LF_far_d_c(c):\n",
    "    return cross_sentence_rule_regex_search_btw_BA(c, '.{100,5000}', 2, session)\n",
    "\n",
    "def LF_risk_d(c):\n",
    "    return cross_sentence_rule_regex_search_before_B(c, 'risk of ', 1, session)\n",
    "\n",
    "def LF_develop_d_following_c(c):\n",
    "    return 1 if re.search(r'develop.{0,25}{{B}}.{0,25}following.{0,25}{{A}}', cross_sentence_get_tagged_text(c, session), flags=re.I) else 0\n",
    "\n",
    "procedure, following = ['inject', 'administrat'], ['following']\n",
    "def LF_d_following_c(c):\n",
    "    return 1 if re.search('{{B}}.{0,50}' + ltp(following) + '.{0,20}{{A}}.{0,50}' + ltp(procedure), cross_sentence_get_tagged_text(c, session), flags=re.I) else 0\n",
    "\n",
    "def LF_measure(c):\n",
    "    return 2 if re.search('measur.{0,75}{{A}}', cross_sentence_get_tagged_text(c, session), flags=re.I) else 0\n",
    "\n",
    "def LF_level(c):\n",
    "    return 2 if re.search('{{A}}.{0,25} level', cross_sentence_get_tagged_text(c, session), flags=re.I) else 0\n",
    "\n",
    "def LF_neg_d(c):\n",
    "    return 2 if re.search('(none|not|no) .{0,25}{{B}}', cross_sentence_get_tagged_text(c, session), flags=re.I) else 0\n",
    "\n",
    "WEAK_PHRASES = ['none', 'although', 'was carried out', 'was conducted',\n",
    "                'seems', 'suggests', 'risk', 'implicated',\n",
    "               'the aim', 'to (investigate|assess|study)']\n",
    "\n",
    "WEAK_RGX = r'|'.join(WEAK_PHRASES)\n",
    "\n",
    "def LF_weak_assertions(c):\n",
    "    return 2 if re.search(WEAK_RGX, cross_sentence_get_tagged_text(c, session), flags=re.I) else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composite LFs\n",
    "\n",
    "The following LFs take some of the strongest distant supervision and text pattern LFs, and combine them to form more specific LFs. These LFs introduce some obvious dependencies within the LF set, which we will model later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LF_ctd_marker_c_d(c):\n",
    "    return LF_c_d(c) * cand_in_ctd_marker(c)\n",
    "\n",
    "def LF_ctd_marker_induce(c):\n",
    "    return (LF_c_induced_d(c) or LF_d_induced_by_c_tight(c)) * cand_in_ctd_marker(c)\n",
    "\n",
    "def LF_ctd_therapy_treat(c):\n",
    "    return LF_c_treat_d_wide(c) * cand_in_ctd_therapy(c)\n",
    "\n",
    "def LF_ctd_unspecified_treat(c):\n",
    "    return LF_c_treat_d_wide(c) * cand_in_ctd_unspecified(c)\n",
    "\n",
    "def LF_ctd_unspecified_induce(c):\n",
    "    return (LF_c_induced_d(c) or LF_d_induced_by_c_tight(c)) * cand_in_ctd_unspecified(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rules based on context hierarchy\n",
    "\n",
    "These last two rules will make use of the context hierarchy. The first checks if there is a chemical mention much closer to the candidate's disease mention than the candidate's chemical mention. The second does the analog for diseases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_keywords = set(['treat', 'effective', 'prevent', 'resistant', 'slow', 'promise', 'therap',\n",
    "                  'cause', 'caused', 'induce', 'due', 'induced'])\n",
    "\n",
    "def LF_pos_keywords_in_dep_path(c):\n",
    "\n",
    "    path = get_dep_path(c, session)\n",
    "    words = set([word for (word, dep_type) in path])\n",
    "\n",
    "    return 1 if len(words.intersection(pos_keywords)) > 0 else 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the LFs on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LFs = [\n",
    "    LF_pos_keywords_in_dep_path,\n",
    "    LF_c_cause_d,\n",
    "    LF_c_d,\n",
    "    LF_c_induced_d,\n",
    "    LF_c_treat_d,\n",
    "    LF_c_treat_d_wide,\n",
    "    LF_ctd_marker_c_d,\n",
    "    LF_ctd_marker_induce,\n",
    "    LF_ctd_therapy_treat,\n",
    "    LF_ctd_unspecified_treat,\n",
    "    LF_ctd_unspecified_induce,\n",
    "    LF_d_following_c,\n",
    "    LF_d_induced_by_c,\n",
    "    LF_d_induced_by_c_tight,\n",
    "    LF_d_treat_c,\n",
    "    LF_develop_d_following_c,\n",
    "    LF_far_c_d,\n",
    "    LF_far_d_c,\n",
    "    LF_improve_before_disease,\n",
    "    LF_in_ctd_therapy,\n",
    "    LF_in_ctd_marker,\n",
    "    LF_in_patient_with,\n",
    "    LF_induce,\n",
    "    LF_induce_name,\n",
    "    LF_induced_other,\n",
    "    LF_level,\n",
    "    LF_measure,\n",
    "    LF_neg_d,\n",
    "    LF_risk_d,\n",
    "    LF_treat_d,\n",
    "    LF_uncertain,\n",
    "    LF_weak_assertions,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelAnnotator\n",
    "labeler = LabelAnnotator(lfs=LFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16/21300 [00:00<02:19, 152.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clearing existing...\n",
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21300/21300 [02:00<00:00, 176.60it/s]\n"
     ]
    }
   ],
   "source": [
    "L_train = labeler.apply(split = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felipe/Projects/metal/metal/analysis.py:13: UserWarning: \n",
      "This call to matplotlib.use() has no effect because the backend has already\n",
      "been chosen; matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "The backend was *originally* set to 'module://ipykernel.pylab.backend_inline' by the following code:\n",
      "  File \"/anaconda3/envs/snorkel/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"/anaconda3/envs/snorkel/lib/python3.6/runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/anaconda3/envs/snorkel/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/anaconda3/envs/snorkel/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n",
      "    app.start()\n",
      "  File \"/anaconda3/envs/snorkel/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 486, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/anaconda3/envs/snorkel/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 127, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/anaconda3/envs/snorkel/lib/python3.6/asyncio/base_events.py\", line 422, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/anaconda3/envs/snorkel/lib/python3.6/asyncio/base_events.py\", line 1432, in _run_once\n",
      "    handle._run()\n",
      "  File \"/anaconda3/envs/snorkel/lib/python3.6/asyncio/events.py\", line 145, in _run\n",
      "    self._callback(*self._args)\n",
      "  File \"/anaconda3/envs/snorkel/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 117, in _handle_events\n",
      "    handler_func(fileobj, events)\n",
      "  File \"/anaconda3/envs/snorkel/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/anaconda3/envs/snorkel/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n",
      "    self._handle_recv()\n",
      "  File \"/anaconda3/envs/snorkel/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n",
      "    self._run_callback(callback, msg)\n",
      "  File \"/anaconda3/envs/snorkel/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/anaconda3/envs/snorkel/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/anaconda3/envs/snorkel/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/anaconda3/envs/snorkel/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/anaconda3/envs/snorkel/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n",
      "    user_expressions, allow_stdin)\n",
      "  File \"/anaconda3/envs/snorkel/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"/anaconda3/envs/snorkel/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"/anaconda3/envs/snorkel/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2666, in run_cell\n",
      "    self.events.trigger('post_run_cell', result)\n",
      "  File \"/anaconda3/envs/snorkel/lib/python3.6/site-packages/IPython/core/events.py\", line 88, in trigger\n",
      "    func(*args, **kwargs)\n",
      "  File \"/anaconda3/envs/snorkel/lib/python3.6/site-packages/ipykernel/pylab/backend_inline.py\", line 160, in configure_once\n",
      "    activate_matplotlib(backend)\n",
      "  File \"/anaconda3/envs/snorkel/lib/python3.6/site-packages/IPython/core/pylabtools.py\", line 311, in activate_matplotlib\n",
      "    matplotlib.pyplot.switch_backend(backend)\n",
      "  File \"/anaconda3/envs/snorkel/lib/python3.6/site-packages/matplotlib/pyplot.py\", line 231, in switch_backend\n",
      "    matplotlib.use(newbackend, warn=False, force=True)\n",
      "  File \"/anaconda3/envs/snorkel/lib/python3.6/site-packages/matplotlib/__init__.py\", line 1410, in use\n",
      "    reload(sys.modules['matplotlib.backends'])\n",
      "  File \"/anaconda3/envs/snorkel/lib/python3.6/importlib/__init__.py\", line 166, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"/anaconda3/envs/snorkel/lib/python3.6/site-packages/matplotlib/backends/__init__.py\", line 16, in <module>\n",
      "    line for line in traceback.format_stack()\n",
      "\n",
      "\n",
      "  matplotlib.use(\"TkAgg\")\n"
     ]
    }
   ],
   "source": [
    "from metal.label_model import LabelModel\n",
    "label_model = LabelModel(k=2, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnotatorLabels created: 0\n",
      "Computing O...\n",
      "Estimating \\mu...\n",
      "[E:0]\tTrain Loss: 4.893\n",
      "[E:50]\tTrain Loss: 0.029\n",
      "[E:100]\tTrain Loss: 0.026\n",
      "[E:150]\tTrain Loss: 0.025\n",
      "[E:200]\tTrain Loss: 0.025\n",
      "[E:250]\tTrain Loss: 0.024\n",
      "[E:300]\tTrain Loss: 0.020\n",
      "[E:350]\tTrain Loss: 0.013\n",
      "[E:400]\tTrain Loss: 0.010\n",
      "[E:450]\tTrain Loss: 0.009\n",
      "[E:500]\tTrain Loss: 0.008\n",
      "[E:550]\tTrain Loss: 0.008\n",
      "[E:599]\tTrain Loss: 0.008\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from snorkel.annotations import load_gold_labels_array\n",
    "from load_external_annotations import load_external_labels\n",
    "import numpy as np\n",
    "\n",
    "USE_DEV_BALANCE = True\n",
    "if USE_DEV_BALANCE:\n",
    "    load_external_labels(session, ChemicalDisease, split=1, annotator='gold')\n",
    "    L_gold_dev = load_gold_labels_array(session, annotator_name='gold', split=1)\n",
    "\n",
    "    l = []\n",
    "    for i in L_gold_dev:\n",
    "        if i == -1:\n",
    "            l.append(2)\n",
    "        else:\n",
    "            l.append(i)\n",
    "    y_dev = np.asarray(l)\n",
    "\n",
    "    label_model.train(L_train, Y_dev=y_dev, n_epochs=600, print_every=50)\n",
    "else:\n",
    "    label_model.train(L_train, n_epochs=600, print_every=50)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AnnotatorLabels created: 11973\n",
      "Clearing existing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 16/11973 [00:00<01:16, 156.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running UDF...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11973/11973 [01:11<00:00, 168.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.641\n",
      "Precision: 0.369\n",
      "Recall: 0.286\n",
      "F1: 0.322\n",
      "        y=1    y=2   \n",
      " l=1   1022   2548   \n",
      " l=2   1746   6657   \n",
      "[[1022 2548]\n",
      " [1746 6657]]\n"
     ]
    }
   ],
   "source": [
    "from metal.analysis import confusion_matrix\n",
    "\n",
    "EVAL_SPLIT = 2\n",
    "load_external_labels(session, ChemicalDisease, split=EVAL_SPLIT, annotator='gold')\n",
    "L_gold_eval = load_gold_labels_array(session, annotator_name='gold', split=EVAL_SPLIT)\n",
    "\n",
    "l = []\n",
    "for i in L_gold_eval:\n",
    "    if i == -1:\n",
    "        l.append(2)\n",
    "    else:\n",
    "        l.append(i)\n",
    "y_eval = np.asarray(l)\n",
    "L_eval = labeler.apply(split=EVAL_SPLIT)\n",
    "\n",
    "score = label_model.score(L_eval, y_eval)\n",
    "scores = label_model.score(L_eval, y_eval, metric=['precision', 'recall', 'f1'])\n",
    "\n",
    "Y_eval_p = label_model.predict(L_eval)\n",
    "cm = confusion_matrix(y_eval, Y_eval_p)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.472\n",
      "Recall: 0.659\n",
      "F1: 0.550\n",
      "        y=1    y=2   \n",
      " l=1   2343   1227   \n",
      " l=2   2655   5748   \n",
      "[[2343 1227]\n",
      " [2655 5748]]\n"
     ]
    }
   ],
   "source": [
    "from metal.label_model.baselines import MajorityLabelVoter\n",
    "\n",
    "mv = MajorityLabelVoter(seed=123)\n",
    "scores = mv.score(L_eval, y_eval, metric=['precision', 'recall', 'f1'])\n",
    "Y_eval_p = mv.predict(L_eval)\n",
    "cm = confusion_matrix(y_eval, Y_eval_p)\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
